---
title: "Nachrichten Tweets zum Thema Bamf"
output: html_document
---

```{r message=FALSE, warning=FALSE}
library(rtweet)
library(plotly)
library(dplyr)
library(ggplot2)
library(rvest)
library(tidyr)

rm(list = ls())
knitr::opts_chunk$set(message=FALSE, warning=FALSE)

# Functions
linebreak <- function(s) {
  gsub('(.{1,70})(\\s|$)', '\\1\n', s)
}

Mycol <- RColorBrewer::brewer.pal(8, "Dark2")
```

```{r eval=FALSE, include=FALSE}
rt <- search_tweets("bamf AND filter:news AND lang:de", 
                    n=15000, 
                    include_rts = F)

save(rt, file = paste0("../data/",hashtag, 
                       Sys.Date(),".Rda"))
```

Alle Tweets der vergangenen Tage zum Thema "BAMF", die einen Link zu einem Nachrichtenartikel beinhalten. Die Tweets wurden über die REST API mit Hilfe des R packetes "rtweet" erhoben. Der gesamte Code ist [hier](https://github.com/franziloew/news_tweets/tree/master/docs) einzusehen. 

Folgende Variablen sind in unserem Datensatz vorhanden. 

```{r}
load("../data/#bamf2018-05-31.Rda")

colnames(rt)
```

```{r fig.width=10}
ts_plot(rt,"1 hour") +
  theme(plot.title = element_text(face = "bold")) +
  labs(
    x = NULL, y = NULL,
    title = "Nachrichten-Tweets zum Thema 'BAMF'",
    subtitle = "Tweets, die einen Link zu einer Nachrichtenseite beinhalten\nund das Wort 'BAMF' beinhaltet haben"
  )
```


### Welche Tweets wurden in diesem Zeitraum am häufigsten geteilt?

Die top 20 sind: 
```{r}
rt %>%
  dplyr::select(screen_name, text, retweet_count) %>%
  group_by(screen_name, text) %>%
  summarise(retweet_count = sum(retweet_count)) %>%
  arrange(desc(retweet_count)) %>%
  .[1:20,] %>%
  htmlTable::htmlTable(align="l")
```

### Welche Tweets wurde am meisten favorisiert? 

Top 20:
```{r}
rt %>%
  dplyr::select(screen_name, text, favorite_count) %>%
  group_by(screen_name, text) %>%
  summarise(favorite_count = sum(favorite_count)) %>%
  arrange(desc(favorite_count)) %>%
  .[1:20,] %>%
  htmlTable::htmlTable(align="l")
```

```{r fig.height=10, fig.width=7, message=FALSE, warning=FALSE}
rt %>%
  group_by(screen_name) %>%
  tally(sort = TRUE) -> name_table

name_table %>%
  top_n(50, n) %>%
  ggplot(aes(reorder(screen_name,n),n)) +
  geom_col(fill = Mycol[1], alpha = 0.6) +
  coord_flip() +
  labs(
    x = NULL,
    y = NULL,
    title = "Top 50 Twitter Nutzer...",
    subtitle = "...die einen Tweet zu 'Bamf' gesendet haben"
  ) 
```

```{r fig.height=10, fig.width=7, message=FALSE, warning=FALSE}
rt$hashtags %>%
  unlist() %>%
  na.omit() %>%
  table() %>%
  sort(decreasing = TRUE) %>%
  tibble::as_tibble() -> hash_table

colnames(hash_table) <- c("hashtag", "count")

hash_table %>%
  top_n(50, count) %>%
  filter(!grepl("bamf",hashtag, ignore.case = T)) %>%
  ggplot( aes(reorder(hashtag,count), count)) +
  geom_col(fill = Mycol[1], alpha = 0.6) +
  coord_flip() +
  labs(
    x = NULL,
    y = NULL,
    title = "Top 50 Hashtags...",
    subtitle = "...die im Zusammenhang mit 'Bamf' in einem Tweet verwendet wurden"
  ) 
```

```{r fig.height=10, fig.width=7, message=FALSE, warning=FALSE}
rt$mentions_screen_name %>%
  unlist() %>%
  na.omit() %>%
  table() %>%
  sort(decreasing = TRUE) %>%
  tibble::as_tibble() -> mentions_table

colnames(mentions_table) <- c("mentions", "count")

mentions_table %>%
  top_n(50, count) %>%
  ggplot( aes(reorder(mentions,count), count)) +
  geom_col(fill = Mycol[1], alpha = 0.6) +
  coord_flip() +
  labs(
    x = NULL,
    y = NULL,
    title = "Top 50 Profil Nennungen...",
    subtitle = "...die im Zusammenhang mit 'Bamf' in einem Tweet verwendet wurden"
  ) 
```

```{r eval=FALSE, include=FALSE}
# get urls of each tweet
df <- rt %>%
  mutate(hash_clean1 = NA,
         hash_clean2 = NA,
         url1 = NA,
         url2 = NA,
         mentions1 = NA,
         mentions2 = NA)


for (i in seq(length(df$status_id))) {
  
  df$hash_clean1[i] <- df$hashtags[[i]][1]
  df$hash_clean2[i] <- df$hashtags[[i]][2]
  df$url1[i] <- df$urls_expanded_url[[i]][1]
  df$url2[i] <- df$urls_expanded_url[[i]][2]
  df$mentions1[i] <- df$mentions_screen_name[[i]][1]
  df$mentions2[i] <- df$mentions_screen_name[[i]][2]
}
```

```{r eval=FALSE, include=FALSE}
# scrape title, sitename and description from meta tags of the website url.

# Use 100 most tweeted articles
check_urls <- df %>%
  group_by(url1) %>%
  tally(sort = T) %>%
  .[1:100,]

# these are the meta tags we want to scrape
keeps <- c("og:title","og:site_name","og:description")

for (i in 1:nrow(check_urls)) {
  
  url <- check_urls$url1[i]
  
  meta <- read_html(url) %>% 
    html_nodes("head") %>%
    html_nodes("meta")
  
  temp.df <- bind_rows(lapply(xml_attrs(meta), 
                              function(x) data.frame(as.list(x), stringsAsFactors=FALSE
                                                     )
                              )
                       )
  
  temp.df <- temp.df %>% 
  filter(property %in% keeps) %>%
  select(content, property) %>%
  mutate(property = gsub("og:","",property)) %>%
  distinct(property, .keep_all = TRUE) %>%
  tidyr::spread(property, content)
  
  if("title" %in% colnames(temp.df)) {
    check_urls$title[i] <- temp.df$title
  } else {
    check_urls$title[i] <- NA
  }
  
  if("site_name" %in% colnames(temp.df)) {
    check_urls$site_name[i] <- temp.df$site_name
  } else {
    check_urls$site_name[i] <- NA
  }
  
  if("description" %in% colnames(temp.df)) {
    check_urls$description[i] <- temp.df$description
  } else {
    check_urls$description[i] <- NA
  }
  
  print(i)

}
```

```{r eval=FALSE, include=FALSE}
# combine the article information with the original dataframe
df <- left_join(df, check_urls, by="url1")

save(rt, df, file = paste0("../data/",hashtag, Sys.Date(),".Rda"))
```

### Welche Artikel wurden am häfigsten geteilt?

```{r}
df %>%
  group_by(title, site_name) %>%
  tally(sort = TRUE) %>%
  htmlTable::htmlTable(align = "l")
```

### Welche Hashtags wurden je News-Website am häufigsten verwendet?

```{r fig.height=16, fig.width=8}
df %>%
  filter(!is.na(title)) %>%
  filter(!is.na(hash_clean1)) %>%
  filter(!grepl("bamf",hash_clean1, ignore.case = T)) %>%
  group_by(site_name, hash_clean1) %>%
  summarise(total = n()) %>%
  arrange(desc(total), .by_group = TRUE) %>%
  slice(1:15) %>%
  ggplot(aes(reorder(hash_clean1,total),total)) +
  geom_col(fill = Mycol[1], alpha=0.6) +
  coord_flip() +
  facet_wrap(~site_name, scales = "free",
             ncol = 2) +
  labs(
    x = NULL,
    y = NULL
  )
```

### Welche Wörter wurden im Zusammenhang mit diesen Artikeln verwendet?

```{r}
df_text <- df %>%
  filter(!is.na(site_name)) %>%
  select(text, site_name)
```

```{r fig.height=14, fig.width=8}
tidy_df <- df_text %>%
  group_by(site_name) %>%
  mutate(
    linenumber = row_number()
  ) %>%
  ungroup() %>%
  tidytext::unnest_tokens(word, text)

# Stopwords entfernen
stopwords <- data_frame(
  word = tm::stopwords("german")
)
custom_sw <- c("https","t.co","via","mal","dass","mehr","bamf")

tidy_df <- tidy_df %>%
  anti_join(stopwords, by="word") %>%
  filter(! word %in% custom_sw)

tidy_df %>%
  group_by(site_name, word) %>%
  summarise(total = n()) %>%
  top_n(10, total) %>%
  ggplot(aes(reorder(word, total),total)) +
  geom_col(fill = Mycol[1], alpha = 0.6) +
  labs(x = NULL, y = "") +
  facet_wrap(~site_name, ncol = 2, scales = "free") +
  coord_flip()
```



